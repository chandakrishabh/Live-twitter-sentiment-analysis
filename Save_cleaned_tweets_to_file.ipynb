{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Save cleaned tweets to file.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0PTDqFbCB61"
      },
      "source": [
        "# This script should take in a list of search words and then save the last N tweets to a csv file after cleaning them\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7bVJHXKCPkb"
      },
      "source": [
        "## Import utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eDKPH8lBu-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5378e0-30e9-4a93-d617-6c4f89d23ecc"
      },
      "source": [
        "!pip install tweepy\n",
        "import tweepy\n",
        "import csv\n",
        "import ssl\n",
        "import time\n",
        "import re\n",
        "from requests.exceptions import Timeout, ConnectionError\n",
        "from requests.packages.urllib3.exceptions import ReadTimeoutError\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "fpath = \"/content/drive/My Drive/Twitter analysis/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (2021.5.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7T4mX_CCgs7"
      },
      "source": [
        "Twitter login credentials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLTeWhRSCDXY"
      },
      "source": [
        "# Add your Twitter API credentials\n",
        "<hidden keys>\n",
        "\n",
        "# Handling authentication with Twitter\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_key, access_secret)\n",
        "\n",
        "# Create a wrapper for the API provided by Twitter\n",
        "api = tweepy.API(auth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUMUjCY4D7Zk"
      },
      "source": [
        "Obtain a list of tweets with provided search words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sYSrOQaCsOZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d350e21e-b89d-48a0-b4f7-f4a9d900e0db"
      },
      "source": [
        "keywords = [input (\"Enter keywords of interest: \")]\n",
        "\n",
        "N_tweets = 500\n",
        "search_words = \"\"\n",
        "for word in keywords:\n",
        "  search_words+=word\n",
        "  search_words+=\"  \"\n",
        "date_since = \"2010-05-28\"\n",
        "tweets = tweepy.Cursor(api.search,\n",
        "              q=search_words,\n",
        "              lang=\"en\",\n",
        "              since=date_since,tweet_mode=\"extended\").items(N_tweets)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter keywords of interest: Olympics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2xfBsHuD3kX"
      },
      "source": [
        "filename = fpath+\"tweets\"\n",
        "with open(filename+\".csv\", 'w') as file:\n",
        "    global writer\n",
        "    writer = csv.writer(file)\n",
        "            # Add a header row to the CSV\n",
        "    writer.writerow([\"Tweet\", \"Matched Keywords\", \"Date\", \"User\",\n",
        "                        \"Source\", \"Tweet ID\", \"Tweet URL\"])\n",
        "    for tweet_object in tweets:\n",
        "      tweet = tweet_object.full_text\n",
        "\n",
        "      '''Convert all named and numeric character references\n",
        "            (e.g. &gt;, &#62;, &#x3e;) in the string s to the\n",
        "            corresponding Unicode characters'''\n",
        "      tweet = (tweet.replace('&amp;', '&').replace('&lt;', '<')\n",
        "                 .replace('&gt;', '>').replace('&quot;', '\"')\n",
        "                 .replace('&#39;', \"'\").replace(';', \" \")\n",
        "                 .replace(r'\\u', \" \").replace(r'\\https://',\" \"))\n",
        "      \n",
        "      #Remove https links from tweet\n",
        "      tweet = re.sub(r'(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-?=%.]+', '', tweet, flags=re.MULTILINE)\n",
        "\n",
        "      # Save the keyword that matches the stream\n",
        "      keyword_matches = []\n",
        "      for word in keywords:\n",
        "          if word.lower() in tweet.lower():\n",
        "              keyword_matches.extend([word])\n",
        "\n",
        "      keywords_strings = \", \".join(str(x) for x in keyword_matches)\n",
        "\n",
        "            # Save other information from the tweet\n",
        "      user = tweet_object.author.screen_name\n",
        "      timeTweet = tweet_object.created_at\n",
        "      source = tweet_object.source\n",
        "      tweetId = tweet_object.id\n",
        "      tweetUrl = \"https://twitter.com/\" + str(user)+ \"/statuses/\" + str(tweetId)\n",
        "\n",
        "        # Exclude retweets, too many mentions and too many hashtags\n",
        "      if not any((('RT @' in tweet, 'RT' in tweet,\n",
        "                      tweet.count('@') >= 2, tweet.count('#') >= 3))):\n",
        "\n",
        "        # Saves the tweet information in a new row of the CSV file\n",
        "        writer.writerow([tweet, keywords_strings, timeTweet,\n",
        "                                user, source, tweetId, tweetUrl])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9F-xNx_PnwS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6a83e8-f007-4e21-86cc-9f35f08a160d"
      },
      "source": [
        "df = pd.read_csv(filename+\".csv\")\n",
        "print(\"Most recent cleaned tweets scraped for '{}' -  \\n\".format(df['Matched Keywords'][0]))\n",
        "df['Tweet'][:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most recent cleaned tweets scraped for 'Olympics' -  \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    shall we sing \"DYHTPS\" reprise from Les Misera...\n",
              "1    funny to think one day there will be no more o...\n",
              "2    Lamda in Japan. Olympics in Japan. Malaysians ...\n",
              "3    Canada picks Damian Warner as flag bearer for ...\n",
              "4    You can’t sum all medals if you aggregate coun...\n",
              "5    @India_AllSports All our Six individual medall...\n",
              "6    Tokyo Games again show what the Olympics are a...\n",
              "7    Tokyo Games again show what the Olympics are a...\n",
              "8                              \"controversial choice\" \n",
              "9    Goodbye #Olympics! I enjoyed you throughly. I’...\n",
              "Name: Tweet, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ElViLdTSH20"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}